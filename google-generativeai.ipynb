{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f0a7f4d-09a8-4c00-ae74-5f34310c2f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-generativeai in c:\\users\\yogen\\anaconda3\\lib\\site-packages (0.3.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.4.0 in c:\\users\\yogen\\anaconda3\\lib\\site-packages (from google-generativeai) (0.4.0)\n",
      "Requirement already satisfied: google-auth in c:\\users\\yogen\\anaconda3\\lib\\site-packages (from google-generativeai) (2.27.0)\n",
      "Requirement already satisfied: google-api-core in c:\\users\\yogen\\anaconda3\\lib\\site-packages (from google-generativeai) (2.16.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\yogen\\anaconda3\\lib\\site-packages (from google-generativeai) (4.9.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\yogen\\anaconda3\\lib\\site-packages (from google-generativeai) (4.25.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\yogen\\anaconda3\\lib\\site-packages (from google-generativeai) (4.65.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\yogen\\anaconda3\\lib\\site-packages (from google-ai-generativelanguage==0.4.0->google-generativeai) (1.23.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\yogen\\anaconda3\\lib\\site-packages (from google-api-core->google-generativeai) (1.62.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in c:\\users\\yogen\\anaconda3\\lib\\site-packages (from google-api-core->google-generativeai) (2.31.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\yogen\\anaconda3\\lib\\site-packages (from google-auth->google-generativeai) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\yogen\\anaconda3\\lib\\site-packages (from google-auth->google-generativeai) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\yogen\\anaconda3\\lib\\site-packages (from google-auth->google-generativeai) (4.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\yogen\\anaconda3\\lib\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\yogen\\anaconda3\\lib\\site-packages (from google-api-core->google-generativeai) (1.60.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\yogen\\anaconda3\\lib\\site-packages (from google-api-core->google-generativeai) (1.60.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\yogen\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth->google-generativeai) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\yogen\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yogen\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yogen\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yogen\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2023.11.17)\n"
     ]
    }
   ],
   "source": [
    "%pip install google-generativeai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd8cab8-23c6-40ca-aa8d-7ce0cbf49fbf",
   "metadata": {},
   "source": [
    "Obtain an API key from AI Studio,https://makersuite.google.com/app/apikey  then configure it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31519519-c84b-4793-918e-bb7cb1aafaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Access the environment variables from the .env file\n",
    "googlellm_api_key = os.environ.get('GOOGLE_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d637abf-1bf7-4f5e-b655-7e68be5ff6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as palm\n",
    "\n",
    "#Next, we configure it using the API key that we generated earlier.\n",
    "palm.configure(api_key=googlellm_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ed62fc8-d815-4f0b-8983-2b236c8a11ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Model(name='models/chat-bison-001',\n",
       "       base_model_id='',\n",
       "       version='001',\n",
       "       display_name='PaLM 2 Chat (Legacy)',\n",
       "       description='A legacy text-only model optimized for chat conversations',\n",
       "       input_token_limit=4096,\n",
       "       output_token_limit=1024,\n",
       "       supported_generation_methods=['generateMessage', 'countMessageTokens'],\n",
       "       temperature=0.25,\n",
       "       top_p=0.95,\n",
       "       top_k=40),\n",
       " Model(name='models/text-bison-001',\n",
       "       base_model_id='',\n",
       "       version='001',\n",
       "       display_name='PaLM 2 (Legacy)',\n",
       "       description='A legacy model that understands text and generates text as an output',\n",
       "       input_token_limit=8196,\n",
       "       output_token_limit=1024,\n",
       "       supported_generation_methods=['generateText', 'countTextTokens', 'createTunedTextModel'],\n",
       "       temperature=0.7,\n",
       "       top_p=0.95,\n",
       "       top_k=40),\n",
       " Model(name='models/embedding-gecko-001',\n",
       "       base_model_id='',\n",
       "       version='001',\n",
       "       display_name='Embedding Gecko',\n",
       "       description='Obtain a distributed representation of a text.',\n",
       "       input_token_limit=1024,\n",
       "       output_token_limit=1,\n",
       "       supported_generation_methods=['embedText', 'countTextTokens'],\n",
       "       temperature=None,\n",
       "       top_p=None,\n",
       "       top_k=None),\n",
       " Model(name='models/gemini-pro',\n",
       "       base_model_id='',\n",
       "       version='001',\n",
       "       display_name='Gemini Pro',\n",
       "       description='The best model for scaling across a wide range of tasks',\n",
       "       input_token_limit=30720,\n",
       "       output_token_limit=2048,\n",
       "       supported_generation_methods=['generateContent', 'countTokens'],\n",
       "       temperature=0.9,\n",
       "       top_p=1.0,\n",
       "       top_k=1),\n",
       " Model(name='models/gemini-pro-vision',\n",
       "       base_model_id='',\n",
       "       version='001',\n",
       "       display_name='Gemini Pro Vision',\n",
       "       description='The best image understanding model to handle a broad range of applications',\n",
       "       input_token_limit=12288,\n",
       "       output_token_limit=4096,\n",
       "       supported_generation_methods=['generateContent', 'countTokens'],\n",
       "       temperature=0.4,\n",
       "       top_p=1.0,\n",
       "       top_k=32),\n",
       " Model(name='models/embedding-001',\n",
       "       base_model_id='',\n",
       "       version='001',\n",
       "       display_name='Embedding 001',\n",
       "       description='Obtain a distributed representation of a text.',\n",
       "       input_token_limit=2048,\n",
       "       output_token_limit=1,\n",
       "       supported_generation_methods=['embedContent', 'countTextTokens'],\n",
       "       temperature=None,\n",
       "       top_p=None,\n",
       "       top_k=None),\n",
       " Model(name='models/aqa',\n",
       "       base_model_id='',\n",
       "       version='001',\n",
       "       display_name='Model that performs Attributed Question Answering.',\n",
       "       description=('Model trained to return answers to questions that are grounded in provided '\n",
       "                    'sources, along with estimating answerable probability.'),\n",
       "       input_token_limit=7168,\n",
       "       output_token_limit=1024,\n",
       "       supported_generation_methods=['generateAnswer'],\n",
       "       temperature=0.2,\n",
       "       top_p=1.0,\n",
       "       top_k=40)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To list the available models, we write the below code:\n",
    " \n",
    "models = [model for model in palm.list_models()]\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e95a26e-1b7c-455f-aab1-189c3fc735f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evening\n"
     ]
    }
   ],
   "source": [
    "#Use palm.generate_text to have the model complete some initial text.\n",
    "response = palm.generate_text(prompt=\"The opposite of Morning is\")\n",
    "print(response.result)  # Evening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780c1247-e215-47e2-81d5-5b6fe6071fea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Langchain V1)",
   "language": "python",
   "name": "langchainv1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
